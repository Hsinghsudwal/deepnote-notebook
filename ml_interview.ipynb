{"cells":[{"cell_type":"code","metadata":{"id":"nsTKIlTSj1Wb","cell_id":"5233d620fdfb448085c3e57d6431dd26","deepnote_cell_type":"code"},"source":"import warnings\nwarnings.filterwarnings('ignore')","block_group":"5233d620fdfb448085c3e57d6431dd26","execution_count":15,"outputs":[],"outputs_reference":null},{"cell_type":"markdown","metadata":{"id":"R1OOjNCchjF5","cell_id":"95e60939f3ba46548e0771c9f7772bef","deepnote_cell_type":"markdown"},"source":"## ML","block_group":"95e60939f3ba46548e0771c9f7772bef"},{"cell_type":"code","metadata":{"id":"wV6v4v9HPFew","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"98f7a463c0994e7e9dd7b8ec5fb607f6","outputId":"ecb0300b-fa3b-43f0-8349-c61d097003a9","allow_embed":true,"deepnote_cell_type":"code"},"source":"import pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.datasets import fetch_california_housing\n\n# Load the California housing dataset with scikit-learn\nX, y = fetch_california_housing(return_X_y=True, as_frame=True)\n\n# Add a constant term to the independent variables\nX = sm.add_constant(X)\n\n# Fit the linear regression model\nmodel = sm.OLS(y, X).fit()\n\n# Print a summary of the model's performance\nprint(model.summary())","block_group":"98f7a463c0994e7e9dd7b8ec5fb607f6","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            MedHouseVal   R-squared:                       0.606\nModel:                            OLS   Adj. R-squared:                  0.606\nMethod:                 Least Squares   F-statistic:                     3970.\nDate:                Mon, 06 Feb 2023   Prob (F-statistic):               0.00\nTime:                        21:08:49   Log-Likelihood:                -22624.\nNo. Observations:               20640   AIC:                         4.527e+04\nDf Residuals:                   20631   BIC:                         4.534e+04\nDf Model:                           8                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        -36.9419      0.659    -56.067      0.000     -38.233     -35.650\nMedInc         0.4367      0.004    104.054      0.000       0.428       0.445\nHouseAge       0.0094      0.000     21.143      0.000       0.009       0.010\nAveRooms      -0.1073      0.006    -18.235      0.000      -0.119      -0.096\nAveBedrms      0.6451      0.028     22.928      0.000       0.590       0.700\nPopulation -3.976e-06   4.75e-06     -0.837      0.402   -1.33e-05    5.33e-06\nAveOccup      -0.0038      0.000     -7.769      0.000      -0.005      -0.003\nLatitude      -0.4213      0.007    -58.541      0.000      -0.435      -0.407\nLongitude     -0.4345      0.008    -57.682      0.000      -0.449      -0.420\n==============================================================================\nOmnibus:                     4393.650   Durbin-Watson:                   0.885\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            14087.596\nSkew:                           1.082   Prob(JB):                         0.00\nKurtosis:                       6.420   Cond. No.                     2.38e+05\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.38e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"}],"outputs_reference":"s3:deepnote-cell-outputs-production/2d220c44-e4c4-43e2-906b-cd3ae287b12e"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"c317b686ff7b4428a2d41c8d43ada792","deepnote_cell_type":"markdown"},"source":"Below is a more detailed explanation\n- R-squared: The R-squared value is 0.606, which means that 60.6% of the variance in the target variable is explained by the independent variables in the model.\n- Adj. R-squared: The Adj. R-squared value is also 0.606, which means that 60.6% of the variance in the target variable is explained by the independent variables in the model after accounting for the number of independent variables.\n- F-statistic: The F-statistic value is 3970, and the probability (F-statistic) is 0.00, indicating that the model's independent variables are useful in explaining the variation in the target variable.\n- Log-Likelihood: The log-likelihood value is -22624, which indicates that the model provides a reasonable fit to the data.\n- IC: The Information Criteria (IC) value is 4.527e+04, which indicates that the trade-off between fit and complexity is reasonable.\n- BIC: The Bayesian Information Criteria (BIC) is similar to the IC but penalizes models with many parameters more strongly. Lower BIC values indicate a better trade-off between fit and complexity. In this case, the BIC value is 4.534e+04, which indicates that the trade-off between fit and complexity is reasonable.","block_group":"c317b686ff7b4428a2d41c8d43ada792"},{"cell_type":"code","metadata":{"id":"7QDooGxMiX56","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"76da6d4310f948b186667794a15dc90e","outputId":"6ba06580-0086-48d1-a8ce-4e3e309eb7b5","allow_embed":true,"deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# Load the California Housing dataset\ncal_housing = fetch_california_housing()\ndf = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n\n# Add the target variable to the DataFrame\ndf['target'] = cal_housing.target\n\n# set X and y\nX = df.drop('target', axis=1)\ny = df['target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Fit the linear regression model\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n# Predict the target variable using the test data\ny_pred = regressor.predict(X_test)\n\n# calculating performance metrics\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse**0.5\nr2 = r2_score(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\n\n# Print the performance metrics\nprint(f\"Mean Squared Error: {mse}\")\nprint(f\"Root Mean Squared Error: {rmse}\")\nprint(f\"R-squared: {r2}\")\nprint(f\"Mean Absolute Error: {mae}\")","block_group":"76da6d4310f948b186667794a15dc90e","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"Mean Squared Error: 0.5289841670367209\nRoot Mean Squared Error: 0.7273129773603114\nR-squared: 0.5943232652466202\nMean Absolute Error: 0.535126133655451\n"}],"outputs_reference":"dbtable:cell_outputs/d5faa57c-6c31-4b7d-8080-e32e2ea60611"},{"cell_type":"markdown","metadata":{"id":"dgh4Qexvhh6K","cell_id":"7f776e1f724941d88b4691e2a6e26f63","deepnote_cell_type":"markdown"},"source":"## Python","block_group":"7f776e1f724941d88b4691e2a6e26f63"},{"cell_type":"code","metadata":{"id":"1wKsXMCrhi1o","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"141a0b3862654bf9b5323e960f8d6998","outputId":"c476f7e2-8c30-46b3-b5d0-bb99cdba05e1","allow_embed":true,"deepnote_cell_type":"code"},"source":"def threeSum(nums):\n    # sort the array\n    nums.sort()\n    N, result = len(nums), []\n    # iterate through the array\n    for i in range(N):\n        # skip duplicates\n        if i > 0 and nums[i] == nums[i - 1]:\n            continue\n        target = nums[i] * -1\n        s, e = i + 1, N - 1\n        # iterate through the rest of the array to find the other two numbers\n        while s < e:\n            if nums[s] + nums[e] == target:\n                result.append([nums[i], nums[s], nums[e]])\n                s = s + 1\n                # skip duplicates\n                while s < e and nums[s] == nums[s - 1]:\n                    s = s + 1\n            elif nums[s] + nums[e] < target:\n                s = s + 1\n            else:\n                e = e - 1\n    return result\n\nnums = [-1,0,1,2,-1,-4]\nthreeSum(nums)","block_group":"141a0b3862654bf9b5323e960f8d6998","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[[-1, -1, 2], [-1, 0, 1]]"},"metadata":{},"execution_count":19}],"outputs_reference":"dbtable:cell_outputs/d5ed7597-2c65-404f-b307-d12ab9431ef5"},{"cell_type":"code","metadata":{"id":"HoMeZ0h7mqrg","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"bedd209800f54518a473a173a477ff67","outputId":"192846a1-a27e-41fb-f41f-9c1355cb1f94","allow_embed":true,"deepnote_cell_type":"code"},"source":"def lengthOfLongestSubstring(s: str) -> int:\n    seen = {}\n    l = 0\n    output = 0\n    for r in range(len(s)):\n        if s[r] not in seen:\n            output = max(output,r-l+1)\n        else:\n            if seen[s[r]] < l:\n                output = max(output,r-l+1)\n            else:\n                l = seen[s[r]] + 1\n        seen[s[r]] = r\n    return output\n\ns = \"abcabcbb\"\nlengthOfLongestSubstring(s)","block_group":"bedd209800f54518a473a173a477ff67","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{},"execution_count":22}],"outputs_reference":"dbtable:cell_outputs/564a27ee-b765-4968-ad25-93fe5e006d18"},{"cell_type":"code","metadata":{"id":"q2Vsdhdlm0Om","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"5c4e848653cb4e2aba21a54d6b3adbda","outputId":"9c6b8697-b710-45ed-e6d7-19359c0ab3c8","allow_embed":true,"deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\n\n\ndef set_zeroes(df):\n    m, n = df.shape\n    rows, cols = set(), set()\n    \n    for i in range(m):\n        for j in range(n):\n            if df.iloc[i, j] == 0:\n                rows.add(i)\n                cols.add(j)\n                \n    for row in rows:\n        df.iloc[row, :] = 0\n        \n    for col in cols:\n        df.iloc[:, col] = 0\n\ndf = pd.DataFrame(np.random.randint(low=1, high=10, size=(5, 5)))\ndf.iloc[2, 2] = 0\n\nprint(\"before\")\nprint(df)\n\nprint(\"\\nafter\")\nset_zeroes(df)\nprint(df)","block_group":"5c4e848653cb4e2aba21a54d6b3adbda","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"before\n   0  1  2  3  4\n0  1  1  4  7  8\n1  2  5  8  8  7\n2  9  7  0  4  9\n3  8  3  4  1  3\n4  9  6  5  7  6\n\nafter\n   0  1  2  3  4\n0  1  1  0  7  8\n1  2  5  0  8  7\n2  0  0  0  0  0\n3  8  3  0  1  3\n4  9  6  0  7  6\n"}],"outputs_reference":"dbtable:cell_outputs/0e606ceb-e82f-45d4-bf83-859f58327948"},{"cell_type":"code","metadata":{"id":"UXVwqzNmnNJx","cell_id":"3a9e5319f4aa48b290651ca6bd73d26e","deepnote_cell_type":"code"},"source":"","block_group":"3a9e5319f4aa48b290651ca6bd73d26e","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a605a3e6-1564-47b2-94e7-842290ba7692' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"41acbc24e879479f9e96904f3897894d","deepnote_execution_queue":[]}}